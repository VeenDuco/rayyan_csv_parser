{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data Kennisinstituut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Still Missing: Retrieving pubmed ID or DOI. And screening conclusions that are not in the notes column but jumped around need to be traced in the files before throwing away columns.**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction from csv files\n",
    "\n",
    "In this part we will extract data from the csv files that are exported from rayyan. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load in the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np # for np.nan\n",
    "import re # for searching in notes column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all csv files from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['articles_cataract_IOL.csv', 'articles_chronischebekkenpijn_botoxinjectie.csv', 'articles_coeliakie_NCGS.csv', 'articles_COPD_tripletherapy.csv', 'articles_DDH_Pavlik.csv', 'articles_dehydratiekinderen_antiemetica.csv', 'articles_distaleradiusfracturen_operatiefvsconservatief.csv', 'articles_downsyndroom_vruchtbaarheid.csv', 'articles_geboortezorg_agraves.csv', 'articles_HB_HI_fluoxetine.csv', 'articles_HHT_endoscopische_chirurgie .csv', 'articles_influenza_treatment.csv', 'articles_PA_gonadenverwijderen.csv', 'articles_SAB_vochtbeleid.csv', 'articles_schisis_timing_techniek.csv', 'articles_schouderprothese_totaalvshemi.csv', 'articles_sectiofoetalenood.csv', 'articles_septumcorrectie_kinderen.csv', 'articles_uveitis_biologicals.csv', 'articles_vergroot_ovarium_chirurgie.csv']\n"
     ]
    }
   ],
   "source": [
    "# List all .csv files in the current directory\n",
    "csv_files = [file for file in os.listdir('.') if file.endswith('.csv')]\n",
    "\n",
    "# Display the list of .csv files\n",
    "print(csv_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out how many colums each file has (are they equal? -> No). Then find the common column names so we can extract the relevant data from the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[113, 20, 19, 25, 19, 34, 35, 19, 36, 19, 19, 21, 19, 206, 49, 21, 25, 20, 19, 99]\n",
      "Columns present in all files: {'title', 'issue', 'key', 'language', 'authors', 'month', 'volume', 'abstract', 'pubmed_id', 'url', 'publisher', 'journal', 'year', 'notes', 'issn', 'pages', 'day', 'pmc_id', 'location'}\n"
     ]
    }
   ],
   "source": [
    "ncols = [] # number of columns in each file\n",
    "column_sets = []  # List to store the set of columns from each file\n",
    "\n",
    "for file_name in csv_files:\n",
    "    df = pd.read_csv(file_name, sep=';', engine='python')\n",
    "    ncols.append(df.shape[1]) # Append the number of columns to the list\n",
    "    \n",
    "    # Append the set of column names to the list\n",
    "    column_sets.append(set(df.columns))\n",
    "\n",
    "print(ncols)\n",
    "\n",
    "# Find columns present in all files\n",
    "common_columns = set.intersection(*column_sets)\n",
    "print(\"Columns present in all files:\", common_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing irrelevant columns\n",
    "Not all the common columns are relevant so after looking into the content we remove some columns that we don't need to select.\n",
    "\n",
    "Columns that are removes are:\n",
    "- authors\n",
    "- issue\n",
    "- key\n",
    "- language\n",
    "- month\n",
    "- volume\n",
    "- publisher\n",
    "- journal\n",
    "- issn\n",
    "- pages\n",
    "- day\n",
    "- pmc_id\n",
    "- location\n",
    "- year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Cystoscopic evaluation and clinical phenotypin...   \n",
      "1     Interstitial cystitis - intravesical treatment   \n",
      "2  Pharmacotherapy of interstitial cystitis in women   \n",
      "3  Recommendations on the Use of Botulinum Toxin ...   \n",
      "4  Botulinum toxin treatment of pelvic floor diso...   \n",
      "\n",
      "                                            abstract  pubmed_id  \\\n",
      "0  Herein, we aimed to review, report, and discus...        NaN   \n",
      "1  The Guidelines Project, an initiative of the B...        NaN   \n",
      "2  Interstitial cystitis is a condition that affe...        NaN   \n",
      "3  Context: The increasing body of evidence and n...        NaN   \n",
      "4  Background and Objective: Botulinum neurotoxin...        NaN   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://www.embase.com/search/results?subaction...   \n",
      "1  http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=r...   \n",
      "2  http://www.embase.com/search/results?subaction...   \n",
      "3  http://www.embase.com/search/results?subaction...   \n",
      "4  http://www.embase.com/search/results?subaction...   \n",
      "\n",
      "                                               notes  \n",
      "0                                                NaN  \n",
      "1   RAYYAN-INCLUSION: {\"Dick\"=>\"Maybe\", \"k.j.schw...  \n",
      "2  L46157659     2007-02-27 RAYYAN-INCLUSION: {\"D...  \n",
      "3  L50273447     2008-12-17 RAYYAN-INCLUSION: {\"D...  \n",
      "4  L352487028     2008-10-21 RAYYAN-INCLUSION: {\"...  \n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file with semicolon separator\n",
    "df = pd.read_csv(csv_files[1], sep=';', engine='python')\n",
    "# extract relevan columns\n",
    "columns = ['title', 'abstract', 'pubmed_id', 'url', 'notes']\n",
    "# select the relevant columns\n",
    "df_selected = df[columns]\n",
    "# display the first 5 rows\n",
    "print(df_selected.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we want to get\n",
    "What we want to extract in the end is \n",
    "- title\t\n",
    "- abstract\t\n",
    "- doi\t\n",
    "- pmid\t\n",
    "- TI-AB (title-abstract inclusion status)\n",
    "- FT (full-text inclusion status)\n",
    "- GI (guideline inclusion status)\n",
    "\n",
    "Where we can we want to extract as much as possible. Title and abstract will be one to one transferable. DOI or pmid will have to be retrieved somehow, this will require a process of retrieval. From the inclusion status only TI-AB is known now and will have to be taken from the notes column of the csv files. That will require cleaning step within the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               notes  \\\n",
      "0                                                NaN   \n",
      "1   RAYYAN-INCLUSION: {\"Dick\"=>\"Maybe\", \"k.j.schw...   \n",
      "2  L46157659     2007-02-27 RAYYAN-INCLUSION: {\"D...   \n",
      "3  L50273447     2008-12-17 RAYYAN-INCLUSION: {\"D...   \n",
      "4  L352487028     2008-10-21 RAYYAN-INCLUSION: {\"...   \n",
      "\n",
      "                                    inclusion_status  \n",
      "0                                               None  \n",
      "1       {\"Dick\"=>\"Maybe\", \"k.j.schweitzer\"=>\"Maybe\"}  \n",
      "2  {\"Dick\"=>\"Excluded\", \"k.j.schweitzer\"=>\"Exclud...  \n",
      "3  {\"Dick\"=>\"Included\", \"k.j.schweitzer\"=>\"Includ...  \n",
      "4  {\"Dick\"=>\"Included\", \"k.j.schweitzer\"=>\"Includ...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\5507553\\AppData\\Local\\Temp\\ipykernel_12816\\1624620693.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['inclusion_status'] = df_selected['notes'].apply(lambda x: extract_inclusion_status(x) if pd.notnull(x) else None)\n"
     ]
    }
   ],
   "source": [
    "# Function to extract content within {} after \"RAYYAN-INCLUSION:\"\n",
    "def extract_inclusion_status(note):\n",
    "    match = re.search(r'RAYYAN-INCLUSION:\\s*({.*?})', note)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# Apply the function to the 'notes' column\n",
    "df_selected['inclusion_status'] = df_selected['notes'].apply(lambda x: extract_inclusion_status(x) if pd.notnull(x) else None)\n",
    "\n",
    "# Display the first 5 rows with the new column\n",
    "print(df_selected[['notes', 'inclusion_status']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    inclusion_status  \\\n",
      "0                                               None   \n",
      "1       {\"Dick\"=>\"Maybe\", \"k.j.schweitzer\"=>\"Maybe\"}   \n",
      "2  {\"Dick\"=>\"Excluded\", \"k.j.schweitzer\"=>\"Exclud...   \n",
      "3  {\"Dick\"=>\"Included\", \"k.j.schweitzer\"=>\"Includ...   \n",
      "4  {\"Dick\"=>\"Included\", \"k.j.schweitzer\"=>\"Includ...   \n",
      "\n",
      "                        coded_decisions  \n",
      "0                                  None  \n",
      "1  {'Dick': 999, 'k.j.schweitzer': 999}  \n",
      "2      {'Dick': 0, 'k.j.schweitzer': 0}  \n",
      "3      {'Dick': 1, 'k.j.schweitzer': 1}  \n",
      "4      {'Dick': 1, 'k.j.schweitzer': 1}  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\5507553\\AppData\\Local\\Temp\\ipykernel_12816\\2527196334.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['coded_decisions'] = df_selected['inclusion_status'].apply(extract_decisions)\n"
     ]
    }
   ],
   "source": [
    "# Function to map decisions to codes\n",
    "def map_decision(decision):\n",
    "    if decision.lower() == \"excluded\":\n",
    "        return 0\n",
    "    elif decision.lower() == \"included\":\n",
    "        return 1\n",
    "    elif decision.lower() == \"maybe\":\n",
    "        return 999\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Function to extract names and coded decisions from inclusion_status\n",
    "def extract_decisions(inclusion_status):\n",
    "    if pd.isnull(inclusion_status):\n",
    "        return None\n",
    "    decisions = re.findall(r'\"(.*?)\"\\s*=>\\s*\"(.*?)\"', inclusion_status)\n",
    "    return {name: map_decision(decision) for name, decision in decisions}\n",
    "\n",
    "# Apply the function to the 'inclusion_status' column\n",
    "df_selected['coded_decisions'] = df_selected['inclusion_status'].apply(extract_decisions)\n",
    "\n",
    "# Display the first 5 rows with the new column\n",
    "print(df_selected[['inclusion_status', 'coded_decisions']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision on TI-AB classification\n",
    "After discussion between Tim and Duco we decided that the best \"representation\" of the screening process is:\n",
    "- Two exclusions will be exclusion\n",
    "- anything else represents doubt and thus the article will go through to a next phase in screening, thus inclusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        coded_decisions  TI-AB\n",
      "0                                  None    NaN\n",
      "1  {'Dick': 999, 'k.j.schweitzer': 999}    1.0\n",
      "2      {'Dick': 0, 'k.j.schweitzer': 0}    0.0\n",
      "3      {'Dick': 1, 'k.j.schweitzer': 1}    1.0\n",
      "4      {'Dick': 1, 'k.j.schweitzer': 1}    1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\5507553\\AppData\\Local\\Temp\\ipykernel_12816\\2756579335.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['TI-AB'] = df_selected['coded_decisions'].apply(\n"
     ]
    }
   ],
   "source": [
    "# Create the TI-AB column based on the coded_decisions\n",
    "df_selected['TI-AB'] = df_selected['coded_decisions'].apply(\n",
    "    lambda decisions: np.nan if decisions is None or decisions == 'None' else (\n",
    "        0 if decisions and all(decision == 0 for decision in decisions.values()) else 1\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display the first 5 rows with the new column\n",
    "print(df_selected[['coded_decisions', 'TI-AB']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean export\n",
    "\n",
    "Now we need to cleanup the 'df_selected' DataFrame and export the relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  Cystoscopic evaluation and clinical phenotypin...   \n",
      "1     Interstitial cystitis - intravesical treatment   \n",
      "2  Pharmacotherapy of interstitial cystitis in women   \n",
      "3  Recommendations on the Use of Botulinum Toxin ...   \n",
      "4  Botulinum toxin treatment of pelvic floor diso...   \n",
      "\n",
      "                                            abstract  pubmed_id  \\\n",
      "0  Herein, we aimed to review, report, and discus...        NaN   \n",
      "1  The Guidelines Project, an initiative of the B...        NaN   \n",
      "2  Interstitial cystitis is a condition that affe...        NaN   \n",
      "3  Context: The increasing body of evidence and n...        NaN   \n",
      "4  Background and Objective: Botulinum neurotoxin...        NaN   \n",
      "\n",
      "                                                 url  TI-AB  \n",
      "0  http://www.embase.com/search/results?subaction...    NaN  \n",
      "1  http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=r...    1.0  \n",
      "2  http://www.embase.com/search/results?subaction...    0.0  \n",
      "3  http://www.embase.com/search/results?subaction...    1.0  \n",
      "4  http://www.embase.com/search/results?subaction...    1.0  \n"
     ]
    }
   ],
   "source": [
    "# Select the relevant columns from df_selected\n",
    "df_final = df_selected[['title', 'abstract', 'pubmed_id', 'url', 'TI-AB']]\n",
    "\n",
    "# Display the first 5 rows of the final dataframe\n",
    "print(df_final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the df_final DataFrame to a CSV file with the modified name\n",
    "output_file_name = file_name.replace('.csv', '_CLEAN_TRAM.csv')\n",
    "df_final.to_csv(output_file_name, index=False)\n",
    "\n",
    "# Display the name of the output file\n",
    "print(f\"DataFrame exported to {output_file_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
